"""
–ü–æ–ª–Ω—ã–π pipeline –¥–ª—è –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏–∏ —Ç–∞–Ω—Ü–µ–≤–∞–ª—å–Ω—ã—Ö —Ñ–∏–≥—É—Ä
–ó–∞–ø—É—Å–∫–∞–µ—Ç –≤—Å–µ —ç—Ç–∞–ø—ã: –∏–∑–≤–ª–µ—á–µ–Ω–∏–µ –ø–æ–∑, –ø–æ–¥–≥–æ—Ç–æ–≤–∫—É –¥–∞–Ω–Ω—ã—Ö, –æ–±—É—á–µ–Ω–∏–µ –∏ –æ—Ü–µ–Ω–∫—É
"""
import argparse
import sys
from pathlib import Path
import subprocess
import json
import yaml


def run_command(cmd, description):
    """–ó–∞–ø—É—Å–∫–∞–µ—Ç –∫–æ–º–∞–Ω–¥—É —Å –æ–ø–∏—Å–∞–Ω–∏–µ–º"""
    print(f"\n{'='*70}")
    print(f"–®–ê–ì: {description}")
    print(f"{'='*70}")
    print(f"–ö–æ–º–∞–Ω–¥–∞: {' '.join(cmd)}")
    print()
    
    result = subprocess.run(cmd, capture_output=False, text=True)
    
    if result.returncode != 0:
        print(f"\n‚ùå –û—à–∏–±–∫–∞ –Ω–∞ —à–∞–≥–µ: {description}")
        sys.exit(1)
    else:
        print(f"\n‚úì –®–∞–≥ –∑–∞–≤–µ—Ä—à–µ–Ω: {description}")


def main():
    parser = argparse.ArgumentParser(
        description="–ü–æ–ª–Ω—ã–π pipeline –¥–ª—è –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏–∏ —Ç–∞–Ω—Ü–µ–≤–∞–ª—å–Ω—ã—Ö —Ñ–∏–≥—É—Ä"
    )
    
    # –û–±—â–∏–µ –ø–∞—Ä–∞–º–µ—Ç—Ä—ã
    parser.add_argument('--video_dir', type=str, required=True,
                        help='–î–∏—Ä–µ–∫—Ç–æ—Ä–∏—è —Å –≤–∏–¥–µ–æ —Ñ–∞–π–ª–∞–º–∏')
    parser.add_argument('--output_dir', type=str, default='../outputs',
                        help='–ö–æ—Ä–Ω–µ–≤–∞—è –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏—è –¥–ª—è –≤—ã—Ö–æ–¥–Ω—ã—Ö —Ñ–∞–π–ª–æ–≤')
    parser.add_argument('--model_path', type=str,
                        default='../dancepose/models/yolov8s-pose.pt',
                        help='–ü—É—Ç—å –∫ –º–æ–¥–µ–ª–∏ YOLOv8-Pose')
    parser.add_argument('--device', type=str, default='cuda',
                        help='–£—Å—Ç—Ä–æ–π—Å—Ç–≤–æ (cuda –∏–ª–∏ cpu)')
    
    # –ü–∞—Ä–∞–º–µ—Ç—Ä—ã –¥–∞—Ç–∞—Å–µ—Ç–∞
    parser.add_argument('--sequence_length', type=int, default=30,
                        help='–î–ª–∏–Ω–∞ –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ—Å—Ç–∏')
    parser.add_argument('--overlap', type=int, default=15,
                        help='–ü–µ—Ä–µ–∫—Ä—ã—Ç–∏–µ –º–µ–∂–¥—É –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ—Å—Ç—è–º–∏')
    parser.add_argument('--test_size', type=float, default=0.2,
                        help='–†–∞–∑–º–µ—Ä —Ç–µ—Å—Ç–æ–≤–æ–π –≤—ã–±–æ—Ä–∫–∏')
    parser.add_argument('--val_size', type=float, default=0.1,
                        help='–†–∞–∑–º–µ—Ä –≤–∞–ª–∏–¥–∞—Ü–∏–æ–Ω–Ω–æ–π –≤—ã–±–æ—Ä–∫–∏')
    
    # –ü–∞—Ä–∞–º–µ—Ç—Ä—ã –æ–±—É—á–µ–Ω–∏—è
    parser.add_argument('--config', type=str, default='training/config.yaml',
                        help='–ü—É—Ç—å –∫ –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏ –æ–±—É—á–µ–Ω–∏—è')
    parser.add_argument('--num_epochs', type=int, default=None,
                        help='–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ epochs (–ø–µ—Ä–µ–æ–ø—Ä–µ–¥–µ–ª—è–µ—Ç config)')
    parser.add_argument('--batch_size', type=int, default=None,
                        help='–†–∞–∑–º–µ—Ä –±–∞—Ç—á–∞ (–ø–µ—Ä–µ–æ–ø—Ä–µ–¥–µ–ª—è–µ—Ç config)')
    
    # –§–ª–∞–≥–∏ –¥–ª—è –ø—Ä–æ–ø—É—Å–∫–∞ —à–∞–≥–æ–≤
    parser.add_argument('--skip_pose_extraction', action='store_true',
                        help='–ü—Ä–æ–ø—É—Å—Ç–∏—Ç—å –∏–∑–≤–ª–µ—á–µ–Ω–∏–µ –ø–æ–∑')
    parser.add_argument('--skip_dataset_building', action='store_true',
                        help='–ü—Ä–æ–ø—É—Å—Ç–∏—Ç—å –ø–æ—Å—Ç—Ä–æ–µ–Ω–∏–µ –¥–∞—Ç–∞—Å–µ—Ç–∞')
    parser.add_argument('--skip_training', action='store_true',
                        help='–ü—Ä–æ–ø—É—Å—Ç–∏—Ç—å –æ–±—É—á–µ–Ω–∏–µ')
    parser.add_argument('--skip_evaluation', action='store_true',
                        help='–ü—Ä–æ–ø—É—Å—Ç–∏—Ç—å –æ—Ü–µ–Ω–∫—É')
    
    args = parser.parse_args()
    
    # –°–æ–∑–¥–∞–µ–º –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏–∏
    output_dir = Path(args.output_dir)
    poses_dir = output_dir / 'poses'
    dataset_dir = output_dir / 'dataset'
    models_dir = output_dir / 'models'
    eval_dir = output_dir / 'evaluation'
    
    print("\n" + "="*70)
    print("–ü–û–õ–ù–´–ô PIPELINE –ö–õ–ê–°–°–ò–§–ò–ö–ê–¶–ò–ò –¢–ê–ù–¶–ï–í–ê–õ–¨–ù–´–• –§–ò–ì–£–†")
    print("="*70)
    print(f"\n–î–∏—Ä–µ–∫—Ç–æ—Ä–∏—è —Å –≤–∏–¥–µ–æ: {args.video_dir}")
    print(f"–í—ã—Ö–æ–¥–Ω–∞—è –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏—è: {output_dir}")
    print(f"–£—Å—Ç—Ä–æ–π—Å—Ç–≤–æ: {args.device}")
    
    # ===== –®–ê–ì 1: –ò–ó–í–õ–ï–ß–ï–ù–ò–ï –ü–û–ó =====
    if not args.skip_pose_extraction:
        cmd = [
            sys.executable, 'data_preparation/extract_poses.py',
            '--video_dir', args.video_dir,
            '--output_dir', str(poses_dir),
            '--model_path', args.model_path,
            '--device', args.device
        ]
        run_command(cmd, "–ò–∑–≤–ª–µ—á–µ–Ω–∏–µ –ø–æ–∑ –∏–∑ –≤–∏–¥–µ–æ")
    else:
        print("\n‚è≠Ô∏è  –ü—Ä–æ–ø—É—Å–∫–∞–µ–º –∏–∑–≤–ª–µ—á–µ–Ω–∏–µ –ø–æ–∑")
    
    # ===== –®–ê–ì 2: –ü–û–°–¢–†–û–ï–ù–ò–ï –î–ê–¢–ê–°–ï–¢–ê =====
    if not args.skip_dataset_building:
        cmd = [
            sys.executable, 'data_preparation/dataset_builder.py',
            '--poses_dir', str(poses_dir),
            '--output_dir', str(dataset_dir),
            '--sequence_length', str(args.sequence_length),
            '--overlap', str(args.overlap),
            '--test_size', str(args.test_size),
            '--val_size', str(args.val_size)
        ]
        run_command(cmd, "–ü–æ—Å—Ç—Ä–æ–µ–Ω–∏–µ –¥–∞—Ç–∞—Å–µ—Ç–∞")
    else:
        print("\n‚è≠Ô∏è  –ü—Ä–æ–ø—É—Å–∫–∞–µ–º –ø–æ—Å—Ç—Ä–æ–µ–Ω–∏–µ –¥–∞—Ç–∞—Å–µ—Ç–∞")
    
    # –ó–∞–≥—Ä—É–∂–∞–µ–º/–æ–±–Ω–æ–≤–ª—è–µ–º –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—é
    config_path = Path(args.config)
    if config_path.exists():
        with open(config_path, 'r', encoding='utf-8') as f:
            config = yaml.safe_load(f)
    else:
        config = {}
    
    # –ü–µ—Ä–µ–æ–ø—Ä–µ–¥–µ–ª—è–µ–º –ø–∞—Ä–∞–º–µ—Ç—Ä—ã –µ—Å–ª–∏ —É–∫–∞–∑–∞–Ω—ã
    if args.num_epochs is not None:
        config['num_epochs'] = args.num_epochs
    if args.batch_size is not None:
        config['batch_size'] = args.batch_size
    
    # –°–æ—Ö—Ä–∞–Ω—è–µ–º –æ–±–Ω–æ–≤–ª–µ–Ω–Ω—É—é –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—é
    temp_config_path = output_dir / 'temp_config.yaml'
    with open(temp_config_path, 'w', encoding='utf-8') as f:
        yaml.dump(config, f)
    
    # ===== –®–ê–ì 3: –û–ë–£–ß–ï–ù–ò–ï =====
    if not args.skip_training:
        cmd = [
            sys.executable, 'training/train.py',
            '--config', str(temp_config_path),
            '--data_dir', str(dataset_dir),
            '--output_dir', str(models_dir),
            '--device', args.device
        ]
        run_command(cmd, "–û–±—É—á–µ–Ω–∏–µ –º–æ–¥–µ–ª–∏")
    else:
        print("\n‚è≠Ô∏è  –ü—Ä–æ–ø—É—Å–∫–∞–µ–º –æ–±—É—á–µ–Ω–∏–µ")
    
    # ===== –®–ê–ì 4: –û–¶–ï–ù–ö–ê =====
    if not args.skip_evaluation:
        best_model_path = models_dir / 'best_model.pth'
        if best_model_path.exists():
            cmd = [
                sys.executable, 'inference/predict.py',
                '--model_path', str(best_model_path),
                '--data_dir', str(dataset_dir),
                '--output_dir', str(eval_dir),
                '--device', args.device
            ]
            run_command(cmd, "–û—Ü–µ–Ω–∫–∞ –º–æ–¥–µ–ª–∏")
        else:
            print(f"\n‚ö†Ô∏è  –ú–æ–¥–µ–ª—å –Ω–µ –Ω–∞–π–¥–µ–Ω–∞: {best_model_path}")
            print("–ü—Ä–æ–ø—É—Å–∫–∞–µ–º –æ—Ü–µ–Ω–∫—É")
    else:
        print("\n‚è≠Ô∏è  –ü—Ä–æ–ø—É—Å–∫–∞–µ–º –æ—Ü–µ–Ω–∫—É")
    
    # –£–¥–∞–ª—è–µ–º –≤—Ä–µ–º–µ–Ω–Ω—ã–π —Ñ–∞–π–ª –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏
    if temp_config_path.exists():
        temp_config_path.unlink()
    
    # ===== –§–ò–ù–ê–õ–¨–ù–´–ô –û–¢–ß–ï–¢ =====
    print("\n" + "="*70)
    print("PIPELINE –ó–ê–í–ï–†–®–ï–ù")
    print("="*70)
    
    print("\n–†–µ–∑—É–ª—å—Ç–∞—Ç—ã —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã –≤:")
    print(f"  üìÅ –ü–æ–∑—ã:     {poses_dir}")
    print(f"  üìÅ –î–∞—Ç–∞—Å–µ—Ç:  {dataset_dir}")
    print(f"  üìÅ –ú–æ–¥–µ–ª–∏:   {models_dir}")
    print(f"  üìÅ –û—Ü–µ–Ω–∫–∞:   {eval_dir}")
    
    # –í—ã–≤–æ–¥–∏–º –º–µ—Ç—Ä–∏–∫–∏ –µ—Å–ª–∏ –¥–æ—Å—Ç—É–ø–Ω—ã
    metrics_path = eval_dir / 'metrics.json'
    if metrics_path.exists():
        with open(metrics_path, 'r') as f:
            metrics = json.load(f)
        
        print("\nüìä –ú–µ—Ç—Ä–∏–∫–∏ –Ω–∞ —Ç–µ—Å—Ç–æ–≤–æ–π –≤—ã–±–æ—Ä–∫–µ:")
        print(f"  Accuracy:  {metrics['accuracy']:.4f}")
        print(f"  F1 (macro): {metrics['f1_macro']:.4f}")
        print(f"  Precision: {metrics['precision']:.4f}")
        print(f"  Recall:    {metrics['recall']:.4f}")
    
    # –ò–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –æ –∫–ª–∞—Å—Å–∞—Ö
    metadata_path = dataset_dir / 'metadata.json'
    if metadata_path.exists():
        with open(metadata_path, 'r') as f:
            metadata = json.load(f)
        
        print(f"\nüè∑Ô∏è  –ö–ª–∞—Å—Å—ã: {metadata['label_encoder']['classes']}")
        print(f"üìπ –í–∏–¥–µ–æ –æ–±—Ä–∞–±–æ—Ç–∞–Ω–æ: {len(metadata['videos'])}")
    
    print("\n‚úÖ –í—Å–µ –≥–æ—Ç–æ–≤–æ!")
    print("\n–î–ª—è –∞–Ω–∞–ª–∏–∑–∞ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ –æ—Ç–∫—Ä–æ–π—Ç–µ:")
    print(f"  jupyter notebook notebooks/analysis.ipynb")
    print()


if __name__ == "__main__":
    main()


–ü–æ–ª–Ω—ã–π pipeline –¥–ª—è –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏–∏ —Ç–∞–Ω—Ü–µ–≤–∞–ª—å–Ω—ã—Ö —Ñ–∏–≥—É—Ä
–ó–∞–ø—É—Å–∫–∞–µ—Ç –≤—Å–µ —ç—Ç–∞–ø—ã: –∏–∑–≤–ª–µ—á–µ–Ω–∏–µ –ø–æ–∑, –ø–æ–¥–≥–æ—Ç–æ–≤–∫—É –¥–∞–Ω–Ω—ã—Ö, –æ–±—É—á–µ–Ω–∏–µ –∏ –æ—Ü–µ–Ω–∫—É
"""
import argparse
import sys
from pathlib import Path
import subprocess
import json
import yaml


def run_command(cmd, description):
    """–ó–∞–ø—É—Å–∫–∞–µ—Ç –∫–æ–º–∞–Ω–¥—É —Å –æ–ø–∏—Å–∞–Ω–∏–µ–º"""
    print(f"\n{'='*70}")
    print(f"–®–ê–ì: {description}")
    print(f"{'='*70}")
    print(f"–ö–æ–º–∞–Ω–¥–∞: {' '.join(cmd)}")
    print()
    
    result = subprocess.run(cmd, capture_output=False, text=True)
    
    if result.returncode != 0:
        print(f"\n‚ùå –û—à–∏–±–∫–∞ –Ω–∞ —à–∞–≥–µ: {description}")
        sys.exit(1)
    else:
        print(f"\n‚úì –®–∞–≥ –∑–∞–≤–µ—Ä—à–µ–Ω: {description}")


def main():
    parser = argparse.ArgumentParser(
        description="–ü–æ–ª–Ω—ã–π pipeline –¥–ª—è –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏–∏ —Ç–∞–Ω—Ü–µ–≤–∞–ª—å–Ω—ã—Ö —Ñ–∏–≥—É—Ä"
    )
    
    # –û–±—â–∏–µ –ø–∞—Ä–∞–º–µ—Ç—Ä—ã
    parser.add_argument('--video_dir', type=str, required=True,
                        help='–î–∏—Ä–µ–∫—Ç–æ—Ä–∏—è —Å –≤–∏–¥–µ–æ —Ñ–∞–π–ª–∞–º–∏')
    parser.add_argument('--output_dir', type=str, default='../outputs',
                        help='–ö–æ—Ä–Ω–µ–≤–∞—è –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏—è –¥–ª—è –≤—ã—Ö–æ–¥–Ω—ã—Ö —Ñ–∞–π–ª–æ–≤')
    parser.add_argument('--model_path', type=str,
                        default='../dancepose/models/yolov8s-pose.pt',
                        help='–ü—É—Ç—å –∫ –º–æ–¥–µ–ª–∏ YOLOv8-Pose')
    parser.add_argument('--device', type=str, default='cuda',
                        help='–£—Å—Ç—Ä–æ–π—Å—Ç–≤–æ (cuda –∏–ª–∏ cpu)')
    
    # –ü–∞—Ä–∞–º–µ—Ç—Ä—ã –¥–∞—Ç–∞—Å–µ—Ç–∞
    parser.add_argument('--sequence_length', type=int, default=30,
                        help='–î–ª–∏–Ω–∞ –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ—Å—Ç–∏')
    parser.add_argument('--overlap', type=int, default=15,
                        help='–ü–µ—Ä–µ–∫—Ä—ã—Ç–∏–µ –º–µ–∂–¥—É –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ—Å—Ç—è–º–∏')
    parser.add_argument('--test_size', type=float, default=0.2,
                        help='–†–∞–∑–º–µ—Ä —Ç–µ—Å—Ç–æ–≤–æ–π –≤—ã–±–æ—Ä–∫–∏')
    parser.add_argument('--val_size', type=float, default=0.1,
                        help='–†–∞–∑–º–µ—Ä –≤–∞–ª–∏–¥–∞—Ü–∏–æ–Ω–Ω–æ–π –≤—ã–±–æ—Ä–∫–∏')
    
    # –ü–∞—Ä–∞–º–µ—Ç—Ä—ã –æ–±—É—á–µ–Ω–∏—è
    parser.add_argument('--config', type=str, default='training/config.yaml',
                        help='–ü—É—Ç—å –∫ –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏ –æ–±—É—á–µ–Ω–∏—è')
    parser.add_argument('--num_epochs', type=int, default=None,
                        help='–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ epochs (–ø–µ—Ä–µ–æ–ø—Ä–µ–¥–µ–ª—è–µ—Ç config)')
    parser.add_argument('--batch_size', type=int, default=None,
                        help='–†–∞–∑–º–µ—Ä –±–∞—Ç—á–∞ (–ø–µ—Ä–µ–æ–ø—Ä–µ–¥–µ–ª—è–µ—Ç config)')
    
    # –§–ª–∞–≥–∏ –¥–ª—è –ø—Ä–æ–ø—É—Å–∫–∞ —à–∞–≥–æ–≤
    parser.add_argument('--skip_pose_extraction', action='store_true',
                        help='–ü—Ä–æ–ø—É—Å—Ç–∏—Ç—å –∏–∑–≤–ª–µ—á–µ–Ω–∏–µ –ø–æ–∑')
    parser.add_argument('--skip_dataset_building', action='store_true',
                        help='–ü—Ä–æ–ø—É—Å—Ç–∏—Ç—å –ø–æ—Å—Ç—Ä–æ–µ–Ω–∏–µ –¥–∞—Ç–∞—Å–µ—Ç–∞')
    parser.add_argument('--skip_training', action='store_true',
                        help='–ü—Ä–æ–ø—É—Å—Ç–∏—Ç—å –æ–±—É—á–µ–Ω–∏–µ')
    parser.add_argument('--skip_evaluation', action='store_true',
                        help='–ü—Ä–æ–ø—É—Å—Ç–∏—Ç—å –æ—Ü–µ–Ω–∫—É')
    
    args = parser.parse_args()
    
    # –°–æ–∑–¥–∞–µ–º –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏–∏
    output_dir = Path(args.output_dir)
    poses_dir = output_dir / 'poses'
    dataset_dir = output_dir / 'dataset'
    models_dir = output_dir / 'models'
    eval_dir = output_dir / 'evaluation'
    
    print("\n" + "="*70)
    print("–ü–û–õ–ù–´–ô PIPELINE –ö–õ–ê–°–°–ò–§–ò–ö–ê–¶–ò–ò –¢–ê–ù–¶–ï–í–ê–õ–¨–ù–´–• –§–ò–ì–£–†")
    print("="*70)
    print(f"\n–î–∏—Ä–µ–∫—Ç–æ—Ä–∏—è —Å –≤–∏–¥–µ–æ: {args.video_dir}")
    print(f"–í—ã—Ö–æ–¥–Ω–∞—è –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏—è: {output_dir}")
    print(f"–£—Å—Ç—Ä–æ–π—Å—Ç–≤–æ: {args.device}")
    
    # ===== –®–ê–ì 1: –ò–ó–í–õ–ï–ß–ï–ù–ò–ï –ü–û–ó =====
    if not args.skip_pose_extraction:
        cmd = [
            sys.executable, 'data_preparation/extract_poses.py',
            '--video_dir', args.video_dir,
            '--output_dir', str(poses_dir),
            '--model_path', args.model_path,
            '--device', args.device
        ]
        run_command(cmd, "–ò–∑–≤–ª–µ—á–µ–Ω–∏–µ –ø–æ–∑ –∏–∑ –≤–∏–¥–µ–æ")
    else:
        print("\n‚è≠Ô∏è  –ü—Ä–æ–ø—É—Å–∫–∞–µ–º –∏–∑–≤–ª–µ—á–µ–Ω–∏–µ –ø–æ–∑")
    
    # ===== –®–ê–ì 2: –ü–û–°–¢–†–û–ï–ù–ò–ï –î–ê–¢–ê–°–ï–¢–ê =====
    if not args.skip_dataset_building:
        cmd = [
            sys.executable, 'data_preparation/dataset_builder.py',
            '--poses_dir', str(poses_dir),
            '--output_dir', str(dataset_dir),
            '--sequence_length', str(args.sequence_length),
            '--overlap', str(args.overlap),
            '--test_size', str(args.test_size),
            '--val_size', str(args.val_size)
        ]
        run_command(cmd, "–ü–æ—Å—Ç—Ä–æ–µ–Ω–∏–µ –¥–∞—Ç–∞—Å–µ—Ç–∞")
    else:
        print("\n‚è≠Ô∏è  –ü—Ä–æ–ø—É—Å–∫–∞–µ–º –ø–æ—Å—Ç—Ä–æ–µ–Ω–∏–µ –¥–∞—Ç–∞—Å–µ—Ç–∞")
    
    # –ó–∞–≥—Ä—É–∂–∞–µ–º/–æ–±–Ω–æ–≤–ª—è–µ–º –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—é
    config_path = Path(args.config)
    if config_path.exists():
        with open(config_path, 'r', encoding='utf-8') as f:
            config = yaml.safe_load(f)
    else:
        config = {}
    
    # –ü–µ—Ä–µ–æ–ø—Ä–µ–¥–µ–ª—è–µ–º –ø–∞—Ä–∞–º–µ—Ç—Ä—ã –µ—Å–ª–∏ —É–∫–∞–∑–∞–Ω—ã
    if args.num_epochs is not None:
        config['num_epochs'] = args.num_epochs
    if args.batch_size is not None:
        config['batch_size'] = args.batch_size
    
    # –°–æ—Ö—Ä–∞–Ω—è–µ–º –æ–±–Ω–æ–≤–ª–µ–Ω–Ω—É—é –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—é
    temp_config_path = output_dir / 'temp_config.yaml'
    with open(temp_config_path, 'w', encoding='utf-8') as f:
        yaml.dump(config, f)
    
    # ===== –®–ê–ì 3: –û–ë–£–ß–ï–ù–ò–ï =====
    if not args.skip_training:
        cmd = [
            sys.executable, 'training/train.py',
            '--config', str(temp_config_path),
            '--data_dir', str(dataset_dir),
            '--output_dir', str(models_dir),
            '--device', args.device
        ]
        run_command(cmd, "–û–±—É—á–µ–Ω–∏–µ –º–æ–¥–µ–ª–∏")
    else:
        print("\n‚è≠Ô∏è  –ü—Ä–æ–ø—É—Å–∫–∞–µ–º –æ–±—É—á–µ–Ω–∏–µ")
    
    # ===== –®–ê–ì 4: –û–¶–ï–ù–ö–ê =====
    if not args.skip_evaluation:
        best_model_path = models_dir / 'best_model.pth'
        if best_model_path.exists():
            cmd = [
                sys.executable, 'inference/predict.py',
                '--model_path', str(best_model_path),
                '--data_dir', str(dataset_dir),
                '--output_dir', str(eval_dir),
                '--device', args.device
            ]
            run_command(cmd, "–û—Ü–µ–Ω–∫–∞ –º–æ–¥–µ–ª–∏")
        else:
            print(f"\n‚ö†Ô∏è  –ú–æ–¥–µ–ª—å –Ω–µ –Ω–∞–π–¥–µ–Ω–∞: {best_model_path}")
            print("–ü—Ä–æ–ø—É—Å–∫–∞–µ–º –æ—Ü–µ–Ω–∫—É")
    else:
        print("\n‚è≠Ô∏è  –ü—Ä–æ–ø—É—Å–∫–∞–µ–º –æ—Ü–µ–Ω–∫—É")
    
    # –£–¥–∞–ª—è–µ–º –≤—Ä–µ–º–µ–Ω–Ω—ã–π —Ñ–∞–π–ª –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏
    if temp_config_path.exists():
        temp_config_path.unlink()
    
    # ===== –§–ò–ù–ê–õ–¨–ù–´–ô –û–¢–ß–ï–¢ =====
    print("\n" + "="*70)
    print("PIPELINE –ó–ê–í–ï–†–®–ï–ù")
    print("="*70)
    
    print("\n–†–µ–∑—É–ª—å—Ç–∞—Ç—ã —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã –≤:")
    print(f"  üìÅ –ü–æ–∑—ã:     {poses_dir}")
    print(f"  üìÅ –î–∞—Ç–∞—Å–µ—Ç:  {dataset_dir}")
    print(f"  üìÅ –ú–æ–¥–µ–ª–∏:   {models_dir}")
    print(f"  üìÅ –û—Ü–µ–Ω–∫–∞:   {eval_dir}")
    
    # –í—ã–≤–æ–¥–∏–º –º–µ—Ç—Ä–∏–∫–∏ –µ—Å–ª–∏ –¥–æ—Å—Ç—É–ø–Ω—ã
    metrics_path = eval_dir / 'metrics.json'
    if metrics_path.exists():
        with open(metrics_path, 'r') as f:
            metrics = json.load(f)
        
        print("\nüìä –ú–µ—Ç—Ä–∏–∫–∏ –Ω–∞ —Ç–µ—Å—Ç–æ–≤–æ–π –≤—ã–±–æ—Ä–∫–µ:")
        print(f"  Accuracy:  {metrics['accuracy']:.4f}")
        print(f"  F1 (macro): {metrics['f1_macro']:.4f}")
        print(f"  Precision: {metrics['precision']:.4f}")
        print(f"  Recall:    {metrics['recall']:.4f}")
    
    # –ò–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –æ –∫–ª–∞—Å—Å–∞—Ö
    metadata_path = dataset_dir / 'metadata.json'
    if metadata_path.exists():
        with open(metadata_path, 'r') as f:
            metadata = json.load(f)
        
        print(f"\nüè∑Ô∏è  –ö–ª–∞—Å—Å—ã: {metadata['label_encoder']['classes']}")
        print(f"üìπ –í–∏–¥–µ–æ –æ–±—Ä–∞–±–æ—Ç–∞–Ω–æ: {len(metadata['videos'])}")
    
    print("\n‚úÖ –í—Å–µ –≥–æ—Ç–æ–≤–æ!")
    print("\n–î–ª—è –∞–Ω–∞–ª–∏–∑–∞ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ –æ—Ç–∫—Ä–æ–π—Ç–µ:")
    print(f"  jupyter notebook notebooks/analysis.ipynb")
    print()


if __name__ == "__main__":
    main()


